{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đầu vào:\n",
      "     Bank                                               Link  \\\n",
      "0  ABBank  https://cafef.vn/abbank-giam-toi-15-nam-lai-su...   \n",
      "1  ABBank  https://cafef.vn/abbank-va-maybank-tang-cuong-...   \n",
      "2  ABBank  https://cafef.vn/16-ca-nhan-3-to-chuc-so-huu-g...   \n",
      "3  ABBank  https://cafef.vn/abbank-dat-558-ty-dong-loi-nh...   \n",
      "4  ABBank  https://cafef.vn/nhieu-uu-dai-danh-cho-khach-h...   \n",
      "\n",
      "                                               Title  \\\n",
      "0  ABBank giảm tới 1,5%/năm lãi suất cho vay khác...   \n",
      "1  Maybank tăng cường quan hệ hợp tác chiến lược,...   \n",
      "2  16 cá nhân, 3 tổ chức sở hữu gần 67% vốn điều ...   \n",
      "3  ABBANK đạt 558 tỷ đồng lợi nhuận trước thuế tr...   \n",
      "4  Nhiều ưu đãi dành cho khách hàng ABBANK nhân s...   \n",
      "\n",
      "                                         Description         Time_published  \\\n",
      "0  Với mong muốn cùng chung tay tiếp sức, hỗ trợ ...  25-09-2024 - 15:14 PM   \n",
      "1  Vừa qua tại Hà Nội, Ngân hàng TMCP An Bình (AB...  11-09-2024 - 13:04 PM   \n",
      "2  Ngân hàng TMCP An Bình (ABBank - ABB) vừa công...  08-08-2024 - 17:02 PM   \n",
      "3  Kết thúc quý II/2024, Ngân hàng TMCP An Bình (...  01-08-2024 - 08:08 AM   \n",
      "4  Mừng sinh nhật 31 năm, ABBANK đã triển khai nh...  07-06-2024 - 15:30 PM   \n",
      "\n",
      "  Evaluate( Human)  \n",
      "0         Positive  \n",
      "1         Positive  \n",
      "2          Neutral  \n",
      "3         Positive  \n",
      "4         Positive  \n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file Excel và giữ lại các cột cần thiết\n",
    "file_path = 'data_first.xlsx'  # Đường dẫn tới file Excel\n",
    "df = pd.read_excel(file_path, usecols=['Bank', 'Link', 'Title', 'Description', 'Time_published', 'Evaluate( Human)'])\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(\"Dữ liệu đầu vào:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FPT SHOP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6618 - loss: 0.9144 - val_accuracy: 0.2935 - val_loss: 1.4761\n",
      "Epoch 2/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8557 - loss: 0.4167 - val_accuracy: 0.4560 - val_loss: 1.1665\n",
      "Epoch 3/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.3273 - val_accuracy: 0.5590 - val_loss: 1.0042\n",
      "Epoch 4/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2725 - val_accuracy: 0.6233 - val_loss: 0.8466\n",
      "Epoch 5/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2326 - val_accuracy: 0.6688 - val_loss: 0.7408\n",
      "Epoch 6/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.2031 - val_accuracy: 0.7247 - val_loss: 0.6469\n",
      "Epoch 7/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1770 - val_accuracy: 0.7566 - val_loss: 0.5769\n",
      "Epoch 8/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1555 - val_accuracy: 0.7520 - val_loss: 0.5860\n",
      "Epoch 9/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1413 - val_accuracy: 0.8359 - val_loss: 0.4159\n",
      "Epoch 10/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1257 - val_accuracy: 0.8448 - val_loss: 0.3951\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - loss: 0.5964\n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Hàm chuẩn hóa văn bản\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Kiểm tra xem text có phải là chuỗi không\n",
    "        text = text.lower()  # Chuyển về chữ thường\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ dấu câu\n",
    "        return text\n",
    "    return \"\"  # Trả về chuỗi rỗng nếu không phải là chuỗi\n",
    "\n",
    "# Áp dụng chuẩn hóa cho Title và Description\n",
    "df['Title'] = df['Title'].apply(preprocess_text)\n",
    "df['Description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Kết hợp Title và Description\n",
    "df['text'] = df['Title'] + \" \" + df['Description']\n",
    "\n",
    "# Mã hóa nhãn\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Evaluate( Human)'])\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Loại bỏ giá trị NaN nếu có\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Sử dụng TF-IDF để mã hóa\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Sử dụng SMOTE để cân bằng lớp\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_tfidf.toarray(), y_train)\n",
    "\n",
    "# Tính toán trọng số cho các lớp\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_resampled),\n",
    "    y=y_resampled\n",
    ")\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Xây dựng mô hình DNN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_tfidf.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Số lớp tương ứng với số nhãn\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_resampled, y_resampled, epochs=10, batch_size=32, validation_split=0.2, class_weight=class_weights_dict)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "loss, accuracy = model.evaluate(X_test_tfidf.toarray(), y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1364\n",
      "Train Accuracy: 0.95\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - loss: 0.5964\n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình trên tập huấn luyện\n",
    "train_loss, train_accuracy = model.evaluate(X_train_tfidf.toarray(), y_train)\n",
    "print(f'Train Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss, test_accuracy = model.evaluate(X_test_tfidf.toarray(), y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Dự đoán nhãn: Negative\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_title_and_description(title, description):\n",
    " \n",
    "    title_processed = preprocess_text(title)\n",
    "    description_processed = preprocess_text(description)\n",
    "    text_input = title_processed + \" \" + description_processed\n",
    "    \n",
    "    # vector TF-IDF\n",
    "    text_vector = vectorizer.transform([text_input]).toarray()  \n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(text_vector)\n",
    "    predicted_class = np.argmax(prediction, axis=-1) \n",
    "    \n",
    "    return label_encoder.inverse_transform(predicted_class)[0]\n",
    "\n",
    "new_title = \"Tiền trong tài khoản “bốc hơi” vì điện thoại bị chiếm quyền: Ngân hàng chỉ cách bảo vệ an toàn\"\n",
    "new_description = \"Để phòng ngừa rủi ro khách hàng bị chiếm đoạt tài khoản, mất tài sản, nhiều ngân hàng đã phát cảnh báo và chỉ ra cách bảo vệ tài khoản an toàn\"\n",
    "predicted_label = predict_title_and_description(new_title, new_description)\n",
    "\n",
    "print(f'Dự đoán nhãn: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
